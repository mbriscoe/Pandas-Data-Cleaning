{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5f09f35",
   "metadata": {},
   "source": [
    "# Data Cleaning with Python (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8699b89",
   "metadata": {},
   "source": [
    "In this topic, we’ll focus on two essential data cleaning tasks:\n",
    "1. **Handling Duplicates** – Identifying and removing duplicate rows to avoid skewing analysis.\n",
    "2. **Detecting and Handling Outliers** – Identifying outliers that may distort data insights and deciding how to handle them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a97c83",
   "metadata": {},
   "source": [
    "### Import Libraries and Load Data\n",
    "\n",
    "First, we need to import the necessary libraries and load our dataset that was cleaned in Part 1. Pandas is the primary library we’ll use to manipulate our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed8c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv('cleaned_data.csv')\n",
    "\n",
    "# Displaying the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c8de3d",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Handling Duplicates\n",
    "\n",
    "Duplicate rows can occur when data is entered multiple times or combined from multiple sources. Removing these duplicates is crucial to maintain accurate data.\n",
    "\n",
    "-  **Identify Duplicate Rows**  \n",
    "   Use `.duplicated()` to find duplicate rows in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a50fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify duplicate rows\n",
    "duplicates = df[df.duplicated()]\n",
    "print(\"Duplicate Rows:\")\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3860d118",
   "metadata": {},
   "source": [
    "- We can see that there is a presence of duplicate rows. Let's count the total number of rows so that, after removing the duplicate, we can confirm it was successfully removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd0c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total number of rows\n",
    "row_count = df.shape[0] # df.shape[0] returns the number of rows in the DataFrame.\n",
    "print(\"Total number of rows:\", row_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a917b8",
   "metadata": {},
   "source": [
    "### Remove Duplicate Rows\n",
    "Use `.drop_duplicates()` to remove duplicates from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b64556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Verify removal\n",
    "print(\"Number of rows after removing duplicates:\", df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7a79ee",
   "metadata": {},
   "source": [
    "## Additional Tip\n",
    "\n",
    "### Remove Duplicates Based on Specific Columns\n",
    "\n",
    "Sometimes, duplicates in certain columns need to be handled specifically (e.g., `Transaction ID`). To drop duplicates based on specific columns, pass a list of column names to `.drop_duplicates()`.\n",
    "\n",
    "```python\n",
    "# Remove duplicates based on 'Transaction ID' only\n",
    "df = df.drop_duplicates(subset=['Transaction ID'])\n",
    "\n",
    "# Remove duplicates based on multiple columns, such as 'Transaction ID' and 'Customer ID'\n",
    "df = df.drop_duplicates(subset=['Transaction ID', 'Customer ID'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e66136",
   "metadata": {},
   "source": [
    "# 2. Handling Outliers \n",
    "\n",
    "In this topic, we’ll focus on identifying and handling outliers in the `Total Amount` column using two common techniques:\n",
    "1. **Box Plot Technique**\n",
    "2. **Standard Deviation Technique**\n",
    "\n",
    "Outliers can significantly affect data analysis and model performance, so it's important to handle them carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f8fa2a",
   "metadata": {},
   "source": [
    "## a) Using a Box Plot to Identify Outliers\n",
    "\n",
    "The box plot provides a visual overview, allowing us to quickly spot potential outliers. This is useful for initial data exploration and understanding whether any extreme values are present in a particular column. Now, we’ll create a box plot for the `Total Amount` column to quickly spot any outliers in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af273172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before we begin, ensure that the required libraries are imported.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6879c2",
   "metadata": {},
   "source": [
    "The Total Amount column has picked up some whitespace around its name, so let's remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d1fd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename({' Total Amount ': 'Total Amount'}, axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd9bb99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a box plot for 'Total Amount' to visualise outliers\n",
    "plt.figure(figsize=(6, 3)) # Sets the size of the plot.\n",
    "df['Total Amount'].plot(kind='box') # Creates a box plot for the `Total Amount` column.\n",
    "plt.title('Box Plot for Total Amount') # Adding title\n",
    "plt.ylabel('Total Amount') # Adds labels for clarity.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d93cc8",
   "metadata": {},
   "source": [
    "\n",
    "### Interpreting the Box Plot:\n",
    "- The box represents the interquartile range (IQR), where the middle 50% of the data lies.\n",
    "- The line inside the box shows the median.\n",
    "- Points outside the \"whiskers\" (horizontal lines extending from the box) are potential outliers.\n",
    "\n",
    "In our dataset, we can see that there are 3 potential outliers based on the box plot. The box plot is a quick visualisation tool that helps us identify possible outliers in a dataset. However, in cases where we have a defined threshold, it’s often more precise to use the **Standard Deviation (SD) method**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b103ce9f",
   "metadata": {},
   "source": [
    "\n",
    "## b) Identifying Outliers Using the Standard Deviation Technique\n",
    "\n",
    "While box plots are great for visualisation, the **SD method** can be more effective for adjusting or removing outliers, especially when working with threshold values. By using the SD technique, we can precisely define which data points fall outside of the acceptable range based on statistical calculations.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Calculate Mean and Standard Deviation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ae45e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and standard deviation for the 'Total Amount' column\n",
    "mean = df['Total Amount'].mean()\n",
    "std_dev = df['Total Amount'].std()\n",
    "print(\"The mean is: \", mean)\n",
    "print(\"The standard deviation is: \", std_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53222160",
   "metadata": {},
   "source": [
    "### 2. Define Outlier Thresholds\n",
    "\n",
    "Values below `mean - 3 * std_dev` or above `mean + 3 * std_dev` are considered outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac85b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define thresholds\n",
    "upper_bound = mean + 3 * std_dev\n",
    "lower_bound = mean - 3 * std_dev\n",
    "\n",
    "print(\"The upper bound is: \", upper_bound)\n",
    "print(\"The lower bound is: \", lower_bound)\n",
    "print(\"The lower bound is negative, so it's not applicable as the amount cannot be negative.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3651b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Identify outliers in 'Total Amount' based on the standard deviation technique\n",
    "outliers_std_dev = df[(df['Total Amount'] > upper_bound)]\n",
    "print(\"Outliers in 'Total Amount' using Standard Deviation Technique:\")\n",
    "print(outliers_std_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a79d04",
   "metadata": {},
   "source": [
    "- As we have identified this outlier, we should verify with the business if the total amount of 7,574 is a legitimate purchase with a quantity of 100. If confirmed as valid, we retain this value in the dataset. However, when calculating average transaction amounts, consider excluding this outlier to avoid skewing results or use the median for a more representative measure.\n",
    "- If not confirmed, we would handle it appropriately, such as by removing or correcting the entry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e871a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv('cleaned_data_3.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992623a7",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "In this topic, we focused on two essential data cleaning tasks:\n",
    "\n",
    "1. **Handling Duplicates**: We identified and removed duplicate rows to ensure accuracy and prevent skewed analysis.\n",
    "2. **Identifying Outliers**: We used the standard deviation technique and box plots to detect outliers in the `Total Amount` column for further validation.\n",
    "\n",
    "By addressing these issues, we’ve ensured a cleaner dataset for analysis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb948939",
   "metadata": {},
   "source": [
    "# What's Next? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4db902",
   "metadata": {},
   "source": [
    "In the next topic, we will delve into **Data Cleaning with Python (Part 3)**, where we’ll focus on **Feature Engineering and Data Integration**. We will explore combining datasets and creating new features to enhance our analysis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
