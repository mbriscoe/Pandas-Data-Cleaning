{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3154b14",
   "metadata": {},
   "source": [
    "# Data Cleaning with Python (Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc856920",
   "metadata": {},
   "source": [
    "In this topic, we’ll perform data cleaning tasks in Python using Pandas, focusing on:\n",
    "\n",
    "- **Standardising data types** to ensure correct formats.\n",
    "- **Standardising product names and categories** for consistency.\n",
    "- **Handling missing values** to maintain data completeness.\n",
    "\n",
    "After reading the instructions for the step, run the cell to see the results.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8525094",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries and Load Data\n",
    "\n",
    "First, we need to import the necessary libraries and load our dataset. Pandas is the primary library we’ll use to manipulate our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3fb828",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing the Pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Loading the dataset\n",
    "df = pd.read_csv('../inputs/datasets/raw/Customer_Sales_Transaction.xls')\n",
    "\n",
    "# Displaying the first few rows of the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c323695f",
   "metadata": {},
   "source": [
    "### Step 2: Standardise Data Types\n",
    "\n",
    "Ensuring each column has the correct data type is crucial. For example, quantities should be numeric, not formatted as currency. We’ll review the data types and correct any mistakes.\n",
    "\n",
    "- **Check Data Types:** Use `.dtypes` to view the data type of each column.\n",
    "- **Convert the Quantity Column:** If `Quantity` is not already numeric, we’ll convert it to a numeric format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40beee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types of each column\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dfbfde",
   "metadata": {},
   "source": [
    "In Pandas, the `object` data type is a general-purpose type that usually holds strings (text data) but can technically store any Python object. When a column is labeled as `object`, it typically means:\n",
    "\n",
    "- **Text (String) Data**: The most common usage of `object` in Pandas is for columns containing text. For example, names, product categories, and descriptions are often stored as `object` type.\n",
    "\n",
    "- **Mixed Data**: If a column contains a mix of data types (e.g., numbers and strings together), Pandas defaults to the `object` type since it’s more flexible and can accommodate different types.\n",
    "\n",
    "The columns that need corrections include **Transaction Date** and **Quantity**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118f612f",
   "metadata": {},
   "source": [
    "### Correcting Data Types\n",
    "\n",
    "1. **Transaction Date**: Convert to `datetime` format to enable date-specific operations.\n",
    "2. **Quantity**: Convert to `int` or `float`, depending on the nature of the data.\n",
    "\n",
    "Here’s how you might apply these corrections in Python:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bd04e5",
   "metadata": {},
   "source": [
    "### a) Converting `Transaction Date` Data Type to Datetime Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcde7913",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Transaction Date'] = pd.to_datetime(df['Transaction Date'], errors='coerce')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8023bc5",
   "metadata": {},
   "source": [
    "- `pd.to_datetime(..., errors='coerce')`: Converts `Transaction Date` to `datetime` format, setting invalid dates to `NaT` (Not a Time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The transaction date data type is: \", df['Transaction Date'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0794dafd",
   "metadata": {},
   "source": [
    "### b) Converting Quantity data type to `float`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cadb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the pound symbol and convert the Quantity column to float\n",
    "df['Quantity'] = df['Quantity'].replace('[£]', '', regex=True)\n",
    "df['Quantity'] = df['Quantity'].astype(float)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c140e9",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "- `.replace('[£]', '', regex=True)`: Removes the `£` symbol from each entry in the `Quantity` column. The `regex=True` argument allows for pattern matching, so any occurrence of `£` is replaced with an empty string.\n",
    "- `.astype(float)`: Converts the `Quantity` column to a `float` data type after removing the currency symbol, making it ready for numerical analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79845fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The Quantity data type is: \", df['Quantity'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57f9179",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the dataset\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78ce5bd",
   "metadata": {},
   "source": [
    "### Step 3: Standardise Text in Product Name and Product Categories\n",
    "\n",
    "Consistency is essential when analysing categories or product names.\n",
    "\n",
    "- **View Unique Values**: Check unique entries in `Product Name` and `Product Category`.\n",
    "- **Replace Inconsistent Values**: Use `.replace()` to standardise the values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f92b7",
   "metadata": {},
   "source": [
    "### a) Standardise Text in Product Name\n",
    " \n",
    "Inconsistent product names can interfere with grouping and analysis. For example, `Lap Top` and `Laptop` should be treated as the same product. We’ll first check for unique product names and then correct any inconsistencies.\n",
    "\n",
    "- **View Unique Product Names:** Use `.unique()` to get a list of all unique product names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e37efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print unique value in the column 'Product Name'\n",
    "print(df['Product Name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88e2154",
   "metadata": {},
   "source": [
    "- **Replace Inconsistent Values:** Use `.replace()` to correct any misspelled or misformatted names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed32748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace inconsistent product names\n",
    "df['Product Name'] = df['Product Name'].replace({\n",
    "    'Lap Top': 'Laptop'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e070af",
   "metadata": {},
   "source": [
    "- #### Check the unique values to ensure the replacements are done correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe61e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Unique Values again\n",
    "print(df['Product Name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63ad3a7",
   "metadata": {},
   "source": [
    "### b) Standardise Text in Product Category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a82b2d",
   "metadata": {},
   "source": [
    "Like product names, categories should also be consistent to prevent analysis issues. For instance, `electronic` and `Electronics` should be the same category. We’ll use similar steps as above to check and standardise `Product Category`.\n",
    "\n",
    "- **View Unique Categories:** Use `.unique()` to see all entries in `Product Category`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd7b8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Product Category'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44427886",
   "metadata": {},
   "source": [
    "- **Replace Inconsistent Values:** Use `.replace()` to standardize category names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e0cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'electronic' with 'Electronics'\n",
    "df['Product Category'] = df['Product Category'].replace('Electronic', 'Electronics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c121cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'furnitures' with 'Furniture'\n",
    "df['Product Category'] = df['Product Category'].replace('furnitures', 'Furniture')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44286cf5",
   "metadata": {},
   "source": [
    "- #### Check the unique values to ensure the replacements are done correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae1052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Product Category'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c678a8",
   "metadata": {},
   "source": [
    "- We can see that the replacement has been done correctly, but we have noticed a missing value represented by NaN. Now, let's handle the missing values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be0c1fa",
   "metadata": {},
   "source": [
    "### Step 4: Handle Missing Values\n",
    "\n",
    "Let's identify any missing values and handle them appropriately.\n",
    "\n",
    "1. **Check for Missing Values:** Use `.isnull().sum()` to get a count of missing values in each column.\n",
    "2. **Fill Missing Values in Product Category:** Based on context, fill in missing categories (e.g., if `Product Name` is \"Tablet,\" set `Product Category` to \"Electronics\").\n",
    "3. **Impute Missing Customer Ages:** Use the median age to fill in missing values in `Customer Age` as it's less affected by outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57520254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of missing values for each column\n",
    "print(df.isnull().sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48b28b7",
   "metadata": {},
   "source": [
    "- We can see that the columns **Product Category** and **Customer Age** each have one missing value. Lets inspect these rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e5e707",
   "metadata": {},
   "source": [
    "### a) Handling Missing Value in Product Category Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112ad887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print rows where 'Product Category' is null\n",
    "df[df['Product Category'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8a668d",
   "metadata": {},
   "source": [
    "- Here, we see that the product is \"Tablet.\" Therefore, we can handle this missing value by setting the `Product Category` to \"Electronics.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa22407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #import the Numpy Library\n",
    "\n",
    "# Replace NaN values in 'Product Category' with 'Electronics'\n",
    "df['Product Category'] = df['Product Category'].replace(np.nan, 'Electronics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c4970f",
   "metadata": {},
   "source": [
    "- `np.nan` is used to represent missing values (NaN) in the replace function.\n",
    "- This code replaces all `NaN` values in the Product Category column with \"Electronics.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7791e5f0",
   "metadata": {},
   "source": [
    "In this case, we knew there was only one missing value in `Product Category` and that the `Product Name` was \"Tablet.\" Therefore, we used a simple replacement to fill in \"Electronics\" as the category:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Replace NaN values in 'Product Category' with 'Electronics' for a single known missing entry\n",
    "df['Product Category'] = df['Product Category'].replace(np.nan, 'Electronics')\n",
    "\n",
    "However, if there are multiple missing values in `Product Category` for different products, each belonging to a distinct category, we need to be more specific. This approach requires us to target both the product name and the intended category to avoid incorrect replacements.\n",
    "\n",
    "For instance, if we have missing values across several products, we can use a conditional approach to assign the correct category based on `Product Name`. Here’s how we could achieve this:\n",
    "\n",
    "```python\n",
    "# Fill missing 'Product Category' values based on specific 'Product Name' conditions\n",
    "\n",
    "# For rows where 'Product Name' is 'Tablet' and 'Product Category' is missing, set 'Product Category' to 'Electronics'\n",
    "df.loc[(df['Product Name'] == 'Tablet') & (df['Product Category'].isnull()), 'Product Category'] = 'Electronics'\n",
    "\n",
    "# For rows where 'Product Name' is 'Chair' and 'Product Category' is missing, set 'Product Category' to 'Furniture'\n",
    "df.loc[(df['Product Name'] == 'Chair') & (df['Product Category'].isnull()), 'Product Category'] = 'Furniture'\n",
    "\n",
    "# For rows where 'Product Name' is 'Phone' and 'Product Category' is missing, set 'Product Category' to 'Electronics'\n",
    "df.loc[(df['Product Name'] == 'Phone') & (df['Product Category'].isnull()), 'Product Category'] = 'Electronics'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d473d8",
   "metadata": {},
   "source": [
    "### b) Handling Missing Value in Customer Age Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8f0ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print rows where 'Customer Age' is null\n",
    "df[df['Customer Age'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03cd371",
   "metadata": {},
   "source": [
    "- For missing `'Customer Age'`, use the median to fill in these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9110c4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the Median\n",
    "age_median = df['Customer Age'].median()\n",
    "print(age_median) # The median is 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eb1d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace NA values in Customer Age column with median age\n",
    "df['Customer Age'] = df['Customer Age'].fillna(age_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3417d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm no missing values remain in these key columns\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72ab762",
   "metadata": {},
   "source": [
    "## Save the Cleaned Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635b43e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv('cleaned_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc0a48d",
   "metadata": {},
   "source": [
    "In this topic, we:\n",
    "\n",
    "- Corrected data types.\n",
    "- Standardised text values in the `Product Name` and `Product Category` columns.\n",
    "- Handled missing values by filling with appropriate values where possible.\n",
    "\n",
    "By cleaning the data this way, we ensure our dataset is consistent and ready for analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5862e8f9",
   "metadata": {},
   "source": [
    "## What's Next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e93320",
   "metadata": {},
   "source": [
    "In the next topic, Data Cleaning in Python (Part 2), we’ll focus on handling duplicates, detecting outliers, and performing data integration and feature engineering to further improve data quality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
